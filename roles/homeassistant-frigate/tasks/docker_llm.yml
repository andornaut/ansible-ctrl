---
- name: Start LLM Docker containers
  become: true
  vars:
    ollama_volumes:
      - "{{ homeassistantfrigate_required_volumes.localtime }}:/etc/localtime:ro"
      - "{{ homeassistantfrigate_required_volumes.timezone }}:/etc/timezone:ro"
      - "{{ homeassistantfrigate_ollama_required_volumes.data }}:/root/.ollama"

    openwebui_volumes:
      - "{{ homeassistantfrigate_required_volumes.localtime }}:/etc/localtime:ro"
      - "{{ homeassistantfrigate_required_volumes.timezone }}:/etc/timezone:ro"
      - "{{ homeassistantfrigate_openwebui_required_volumes.data }}:/app/backend/data"

  community.docker.docker_compose_v2:
    project_name: homeassistant-frigate-llm
    pull: always
    remove_orphans: true
    definition:
      networks:
        default:
          external: true
          name: homeassistant-frigate_default

      services:
        ollama:
          # http://ollama:11434
          container_name: ollama
          devices: "{{ homeassistantfrigate_ollama_devices }}"
          group_add:
            - "{{ getent_group.render[1] }}"
            - "{{ getent_group.video[1] }}"
          image: "{{ homeassistantfrigate_ollama_docker_image }}"
          restart: unless-stopped
          # https://docs.docker.com/reference/cli/docker/container/run/#security-opt
          # https://docs.docker.com/engine/security/seccomp/#run-without-the-default-seccomp-profile
          security_opt:
            - seccomp=unconfined
          volumes: "{{ ollama_volumes }}"

        openwebui:
          container_name: openwebui
          image: "{{ homeassistantfrigate_openwebui_docker_image }}"
          ports:
            - "{{ homeassistantfrigate_openwebui_port }}:8080"
          restart: unless-stopped
          volumes: "{{ openwebui_volumes }}"
